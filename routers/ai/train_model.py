# train_model.py (ì •ê·œí™”ëœ ì ìˆ˜ ê¸°ë°˜ íšŒê·€ ëª¨ë¸)

import pandas as pd
import numpy as np
from sqlalchemy import create_engine
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
from xgboost import XGBRegressor
import joblib

# âœ… PostgreSQL ì—°ê²°
DATABASE_URL = "postgresql://postgres:bassmate1119@localhost:5432/bass_ai_db"
engine = create_engine(DATABASE_URL)

# âœ… í•™ìŠµ ë°ì´í„° ë¡œë”©
query = """
SELECT latitude, longitude, weather, temperature, wind, time_period,
       created_at AS posted_at, result
FROM training_fishing_data
WHERE latitude IS NOT NULL AND longitude IS NOT NULL AND result IS NOT NULL
"""
df = pd.read_sql(query, engine)

# âœ… ë‚ ì§œ íŒŒìƒ ì»¬ëŸ¼
df['posted_at'] = pd.to_datetime(df['posted_at'])
df['month'] = df['posted_at'].dt.month
df['hour'] = df['posted_at'].dt.hour
df['season'] = df['month'].map({
    12: "winter", 1: "winter", 2: "winter",
    3: "spring", 4: "spring", 5: "spring",
    6: "summer", 7: "summer", 8: "summer",
    9: "fall", 10: "fall", 11: "fall"
})

# âœ… ìˆ˜ì¹˜í˜• ë³€í™˜ + ê²°ì¸¡ì¹˜ ì²˜ë¦¬
df['temperature'] = pd.to_numeric(df['temperature'], errors='coerce')
df['wind'] = pd.to_numeric(df['wind'], errors='coerce')
df['temperature'].fillna(df['temperature'].mean(), inplace=True)
df['wind'].fillna(df['wind'].mean(), inplace=True)

# âœ… ì ìˆ˜ ë³€í™˜: result â†’ ë³„ì  ê¸°ë°˜ ì ìˆ˜ë¡œ (0 â†’ 0.5, 1 â†’ 3.0)
df['score'] = df['result'].map({0: 0.5, 1: 3.0})

# âœ… One-hot ì¸ì½”ë”©
df = pd.get_dummies(df, columns=["weather", "time_period", "season"])

# âœ… ì…ë ¥(X), ì •ë‹µ(y)
X = df.drop(columns=["posted_at", "month", "result", "score"])
y = df["score"]

# âœ… ìŠ¤ì¼€ì¼ë§ ì ìš©
scaler = StandardScaler()
numerical_cols = ["latitude", "longitude", "temperature", "wind", "hour"]
X[numerical_cols] = scaler.fit_transform(X[numerical_cols])

# âœ… ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# âœ… XGBoost íšŒê·€ ëª¨ë¸ êµ¬ì„±
model = XGBRegressor(
    n_estimators=300,
    max_depth=6,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    missing=np.nan
)
model.fit(X_train, y_train)

# âœ… ëª¨ë¸ í‰ê°€
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("\nâœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
print(f"ğŸ“Š í‰ê· ì œê³±ì˜¤ì°¨ (MSE): {mse:.4f}")
print(f"ğŸ“ˆ ê²°ì •ê³„ìˆ˜ (R2 score): {r2:.4f}")

# âœ… ëª¨ë¸ ì €ì¥
joblib.dump(model, "bass_ai_model_latest.pkl")
joblib.dump(scaler, "bass_ai_scaler.pkl")
joblib.dump(X.columns.tolist(), "bass_ai_model_features.pkl")

print("ğŸ’¾ ëª¨ë¸ ë° í”¼ì²˜ ì •ë³´ ì €ì¥ ì™„ë£Œ!")
